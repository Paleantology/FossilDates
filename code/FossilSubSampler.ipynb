{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dendropy\n",
    "import pandas as pd\n",
    "from sys import argv\n",
    "import argparse\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_data_taxon(fossil_df, **kwargs):\n",
    "    '''Pull the oldest fossil in a group. Mandatory: what level (i.e., subfamily, tribe, etc).'''\n",
    "    foss_list = []\n",
    "    for key, value in kwargs.items():\n",
    "        try:\n",
    "          kwargs[\"level\"]\n",
    "        except KeyError:\n",
    "          raise KeyError('level is required is a Required Argument that tells the program from which \\\\\n",
    "                         taxonomic group to sample. Options include subfamily, tribe, genus')  \n",
    "        try:\n",
    "          kwargs[\"age\"]\n",
    "        except KeyError:\n",
    "          raise KeyError('age is required is a Required Argument that specifies how to sample \\\\\n",
    "                          within a taxonomic group. Options include oldest, youngest, random')          \n",
    "        if key == \"level\":\n",
    "            group_key = value.lower()\n",
    "        if key == \"age\":\n",
    "            age_key = value.lower()\n",
    "            if age_key == \"oldest\":\n",
    "                if \"fraction\" in kwargs.keys():\n",
    "                    num_key = kwargs[\"fraction\"]\n",
    "                    oldest_df = fossil_df.groupby(group_key).apply(lambda x: x.nlargest(int(len(x) * num_key), 'max_ma'))[[\"taxon\",\"max_ma\", group_key]]\n",
    "                    oldest_df.to_csv(\"../Data/fossil_tax_unit.tsv\", sep=\"\\t\", index=False)\n",
    "                    oldest_df = oldest_df.drop(group_key, axis=1) \n",
    "                    oldest_df[[\"taxon\",\"age\"]] = oldest_df[[\"taxon\",\"max_ma\"]]\n",
    "                    oldest_df = oldest_df.drop(\"max_ma\", axis=1) \n",
    "                    oldest_df.to_csv(\"../Data/fossil_sample.tsv\", sep=\"\\t\", index=False)\n",
    "                else:\n",
    "                    oldest_df = fossil_df.groupby([group_key]).max()[[\"max_ma\", \"taxon\"]]\n",
    "                    oldest_df = oldest_df.reset_index()\n",
    "                    oldest_df.to_csv(\"../Data/fossil_tax_unit.tsv\", sep=\"\\t\", index=False)\n",
    "                    oldest_df = oldest_df.drop(group_key, axis=1) \n",
    "                    oldest_df[[\"taxon\",\"age\"]] = oldest_df[[\"taxon\",\"max_ma\"]]\n",
    "                    oldest_df = oldest_df.drop(\"max_ma\", axis=1) \n",
    "                    oldest_df.to_csv(\"../Data/fossil_sample.tsv\", sep=\"\\t\", index=False)\n",
    "            elif age_key == \"youngest\":\n",
    "                if \"fraction\" in kwargs.keys():\n",
    "                    num_key = kwargs[\"fraction\"]\n",
    "                    oldest_df = fossil_df.groupby(group_key).apply(lambda x: x.nsmallest(int(len(x) * num_key), 'max_ma'))[[\"taxon\",\"max_ma\", group_key]]\n",
    "                    #                    oldest_df = oldest_df.reset_index()\n",
    "                    oldest_df.to_csv(\"../Data/fossil_tax_unit.tsv\", sep=\"\\t\", index=False)\n",
    "                    oldest_df = oldest_df.drop(group_key, axis=1) \n",
    "                    oldest_df[[\"taxon\",\"age\"]] = oldest_df[[\"taxon\",\"max_ma\"]]\n",
    "                    oldest_df = oldest_df.drop(\"max_ma\", axis=1) \n",
    "                    oldest_df.to_csv(\"../Data/fossil_sample.tsv\", sep=\"\\t\", index=False)\n",
    "                else:\n",
    "                    oldest_df = fossil_df.groupby([group_key]).min()[[\"max_ma\", \"taxon\"]]\n",
    "                    oldest_df = oldest_df.reset_index()\n",
    "                    oldest_df.to_csv(\"../Data/fossil_tax_unit.tsv\", sep=\"\\t\", index=False)\n",
    "                    oldest_df = oldest_df.drop(group_key, axis=1) \n",
    "                    oldest_df[[\"taxon\",\"age\"]] = oldest_df[[\"taxon\",\"max_ma\"]]\n",
    "                    oldest_df = oldest_df.drop(\"max_ma\", axis=1) \n",
    "                    oldest_df.to_csv(\"../Data/fossil_sample.tsv\", sep=\"\\t\", index=False)\n",
    "            elif age_key == \"random\":                    \n",
    "                if \"fraction\" in kwargs.keys():\n",
    "                    num_key = kwargs[\"fraction\"]\n",
    "                    oldest_df = fossil_df.groupby(group_key).apply(lambda x: x.sample(frac=num_key))[[\"taxon\",\"max_ma\", group_key]]\n",
    "                    oldest_df.to_csv(\"../Data/fossil_tax_unit.tsv\", sep=\"\\t\", index=False)\n",
    "                    oldest_df = oldest_df.drop(group_key, axis=1) \n",
    "                    oldest_df[[\"taxon\",\"age\"]] = oldest_df[[\"taxon\",\"max_ma\"]]\n",
    "                    oldest_df = oldest_df.drop(\"max_ma\", axis=1) \n",
    "                    oldest_df.to_csv(\"../Data/fossil_sample.tsv\", sep=\"\\t\", index=False)                    \n",
    "                else:\n",
    "                    oldest_df = fossil_df.groupby(group_key).apply(lambda x: x.sample(1))[[\"max_ma\", \"taxon\"]]\n",
    "                    oldest_df.to_csv(\"../Data/fossil_tax_unit.tsv\", sep=\"\\t\", index=False)\n",
    "                    oldest_df[[\"taxon\",\"age\"]] = oldest_df[[\"taxon\",\"max_ma\"]]\n",
    "                    oldest_df = oldest_df.drop(\"max_ma\", axis=1) \n",
    "                    oldest_df.to_csv(\"../Data/fossil_sample.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_data_taxon(fossil_df, level=\"genus\", age=\"oldest\", fraction=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_data_sampling(fossil_df, **kwargs):\n",
    "    '''Pull fossils relative to time. Mandatory keyword: Strategy. Options: uniform (freq=int), time_dep, time\n",
    "    stratified. If time-stratified, must also provide a list of time bins (with time_bins = list or df)'''\n",
    "    oldest = float(fossil_df[[\"max_ma\"]].max())\n",
    "    assert len(kwargs.items()) > 0, \"No required args provided. Must provide sampling strategy. \\\n",
    "                                     Options: uniform, diversified, time stratified.\"\n",
    "    for key, value in kwargs.items():\n",
    "        try:\n",
    "          kwargs[\"strategy\"]\n",
    "        except KeyError:\n",
    "          raise KeyError('strategy is a Required Argument that tells the program how to sample fossils through time. \\\\\n",
    "                          Options: uniform, time_dep, time stratified. If time-stratified, provide a list of bins.')  \n",
    "        if \"time-stratified\" in kwargs.values():\n",
    "            try:\n",
    "                kwargs[\"time_bins\"]\n",
    "            except KeyError:\n",
    "                raise KeyError('For time-binned sampling, time bins must be specified withe the time_bins kwarg. \\\n",
    "                                Input may be a list of lists specifying sampling, or a dataframe of time bins') \n",
    "        if key == \"strategy\":\n",
    "            type_key = value.lower()\n",
    "        if type_key == \"uniform\":\n",
    "            if \"freq\" in kwargs.keys():\n",
    "                samp_freq = kwargs[\"freq\"]\n",
    "            else:\n",
    "                samp_freq = .1\n",
    "                print(\"Uniform sampling indicated, but no sliding window width. Will assume window is 10% of  \\\\\n",
    "                      age of oldest fossil\")\n",
    "        if type_key == \"time-dep\":\n",
    "            if \"multiplier\" in kwargs.keys():\n",
    "                multi = kwargs[\"multiplier\"]\n",
    "            else:\n",
    "                print(\"Time dependent sampling indicated, but no multiplier. Will assume sampling frequency \\\\\n",
    "                      increases 10% each time bin towards the present\")\n",
    "                samp_freq = 1.1\n",
    "            if \"freq\" in kwargs.keys():\n",
    "                samp_freq = kwargs[\"freq\"]\n",
    "            else:\n",
    "                samp_freq = .1\n",
    "                print(\"Time dependent sampling indicated, but no sliding window width. Will assume window is 10% of  \\\\\n",
    "                      age of oldest fossil\")\n",
    "    bin = float(oldest)*samp_freq\n",
    "    num_bins = round(oldest/bin)\n",
    "    bottom_interval = oldest - bin\n",
    "    l = pd.DataFrame()\n",
    "    \n",
    "    if type_key == \"uniform\":\n",
    "\n",
    "        for x in range(0,num_bins):\n",
    "            bottom_interval = oldest - (bin*(x+1))\n",
    "            top_interval = oldest - (bin*x)\n",
    "            tmp_df = fossil_df[(fossil_df['max_ma'] >= bottom_interval) & (fossil_df['max_ma'] <= top_interval)]\n",
    "            if len(tmp_df) > 1:\n",
    "                if \"number\" in kwargs:\n",
    "                    numb = kwargs[\"number\"]\n",
    "                    if len(tmp_df) >= numb:\n",
    "                        l = l.append(tmp_df.sample(numb))\n",
    "                    else:\n",
    "                        l = l.append(tmp_df.sample(len(tmp_df)))\n",
    "                else: \n",
    "                    l = l.append(tmp_df.sample(1)) \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    if type_key == \"time-dep\":\n",
    "        for x in range(0,num_bins):\n",
    "\n",
    "            bottom_interval = oldest - (bin*(x+1))\n",
    "            top_interval = oldest - (bin*x)\n",
    "            tmp_df = fossil_df[(fossil_df['max_ma'] >= bottom_interval) & (fossil_df['max_ma'] <= top_interval)]\n",
    "            if len(tmp_df) > 1:\n",
    "                if multi > 1:\n",
    "                    multi = 1\n",
    "                numb = round(len(tmp_df)*multi)\n",
    "                l = l.append(tmp_df.sample(numb))\n",
    "            else:\n",
    "                pass      \n",
    "            multi = multi * (1 + multi)\n",
    "            \n",
    "    l = l.drop(['notes', 'reference_no', 'tribe', 'min_ma', 'fossil'], axis=1)\n",
    "    l[[\"taxon\",\"age\", \"subfamily\", \"genus\"]] = l[[\"taxon\",\"max_ma\", \"subfamily\", \"genus\"]]\n",
    "    l.to_csv(\"../Data/fossil_tax_unit.tsv\", index=False)\n",
    "    l = l.drop(['subfamily', 'genus','max_ma'], axis=1)\n",
    "    l.to_csv(\"../Data/fossil_sample.tsv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_data_sampling(fossil_df, strategy=\"time-dep\", multiplier = .05, freq = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_combined_data(fossil_df, phylo_dat, fossils, extant_df):\n",
    "    names_taxon = pd.DataFrame()\n",
    "    tree_names = phylo_dat.taxon_namespace\n",
    "    for name in tree_names.labels():\n",
    "        if name in fossil_df.taxon.values: \n",
    "            names_taxon = names_taxon.append(fossil_df[fossil_df['taxon'].str.contains(name)])\n",
    "        elif name not in fossil_df.taxon.values:\n",
    "            names_taxon = names_taxon.append(extant_df[extant_df['taxon'].str.contains(name)])\n",
    "        else:\n",
    "            names_taxon = names_taxon.append(name)\n",
    "            print(\"{} is not contained in any morphology file, added without data\".format(name))  \n",
    "    names_taxon = names_taxon[[\"taxon\", \"genus\", \"subfamily\"]]\n",
    "    return(names_taxon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df = make_combined_data(fossil_df, phylo_dat, fossils, extant_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_taxon_set(names_df, **kwargs):\n",
    "    n_l = []\n",
    "    nl_dict = {}\n",
    "    lines = []\n",
    "    new_file_name = \"model_FBDP_0.Rev\"\n",
    "    assert len(kwargs.items()) > 0, \"No required args provided. Must provide taxonomic level to construct taxon sets\"\n",
    "    for key, value in kwargs.items():\n",
    "        try:\n",
    "          kwargs[\"level\"]\n",
    "        except KeyError:\n",
    "          raise KeyError('level is a Required Argument that tells the program how to construct clade contraints')  \n",
    "    if key == \"level\":\n",
    "        group_key = str(value.lower()) \n",
    "        n_l = names_df[group_key].unique()\n",
    "        results = names_df.groupby(group_key)['taxon']\n",
    "    for name in n_l:\n",
    "        nl_dict[name] = results.get_group(name).tolist()\n",
    "    for key, value in nl_dict.items():\n",
    "        for item in value:\n",
    "            item = item.strip()\n",
    "        sentence = key + \" = clade(\\\"\" + \"\\\",\\\"\".join(value) + \"\\\")\" + \"\\n\"\n",
    "        lines.append(sentence)\n",
    "    tax_list = \"constraints=v(\" + \",\".join(str(x) for x in nl_dict.keys()) + \")\"\n",
    "    try:\n",
    "        outfile = open(new_file_name,'r+')\n",
    "    except:\n",
    "# if file does not exist, create it\n",
    "        outfile = open(new_file_name,'w')\n",
    "#    with open(new_file_name) as outfile:\n",
    "    with open(\"model_FBDP.Rev\", \"r\") as infile:\n",
    "        for line in infile: \n",
    "            if \"INSERT1\" in line:\n",
    "                outfile.write(line.replace(\"INSERT1\", \"\".join(str(x) for x in lines)))\n",
    "            elif \"INSERT2\" in line:\n",
    "                outfile.write(line.replace(\"INSERT2\", tax_list))\n",
    "            else:\n",
    "                outfile.write(line)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_taxon_set(names_df, level = \"subfamily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--fossil FOSSIL] [--ages AGES]\n",
      "                             [--sample SAMPLE] [--output OUTPUT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-850356df-1421-4ba5-a59d-a982537519d8.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antlab0/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\n",
    "\tparser.add_argument(\"--fossil\", help=\"Path to the csv of fossils.\")\n",
    "\tparser.add_argument(\"--ages\", help=\"Path to data ages TSV or CSV file containing \\\n",
    "\tages of non-contemporaneous tips, if any exist in your analysis.\")\n",
    "\tparser.add_argument(\"--sample\", help=\"How to sample fossils. Options: oldest, proportional, sampling.\")\n",
    "\tparser.add_argument(\"--output\", help=\"Path to where you'd like to write output\")\n",
    "\targs = parser.parse_args()\n",
    "\tif args.set:\n",
    "\t\tdf = args.set\n",
    "\tif args.ages:\n",
    "\t\ttnrs = args.ages\n",
    "\tif args.output:\n",
    "\t\toutfile = args.output\t\t\n",
    "\t\t\n",
    "\tfoss_tax = parse_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fossil_df = pd.read_csv(\"../Data/FossilTNRS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fossils = pd.read_csv(\"../Data/fossil_tax_unit.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "phylo_dat = dendropy.StandardCharacterMatrix.get_from_path(\"../Data/AntMegaMatrixMinusAmbig.nex\", schema=\"nexus\", preserve_underscores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "extant_df = pd.read_csv(\"../Data/morphTNRS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
